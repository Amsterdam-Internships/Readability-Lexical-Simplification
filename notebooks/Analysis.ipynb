{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiphdaEaOLIsEQXqV9f2ZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amsterdam-Internships/Readability-Lexical-Simplification/blob/master/Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All Analyses**\n",
        "This notebook contains the components for the quantitative analysis of the data and model (output)s\n",
        "\n",
        "1.   Subword-tokenization inspection\n",
        "2.   Generation Properties\n",
        "3.   Selection Properties\n",
        "\n"
      ],
      "metadata": {
        "id": "Jv-5zm3TnN0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Installations"
      ],
      "metadata": {
        "id": "XvrSQMxLn3pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install torch\n",
        "!pip install spacy\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "!python -m spacy download en_core_web_sm "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh0K38F9n73N",
        "outputId": "fb7b7ef3-d7b7-4769-cfa9-2ee6967f6edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.5.18.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "P7FchQ-NCR4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnpU_gTJK_1T",
        "outputId": "deb88c00-71f8-414a-d589-38da0b6ad4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Subword Tokenization"
      ],
      "metadata": {
        "id": "W4PnYXhEnvKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "0p9Jf8JMojjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens(file_path, bench=False):\n",
        "  all_annos =[]\n",
        "  complex_words = []\n",
        "\n",
        "  if bench:\n",
        "    with open(file_path, 'r',encoding=\"utf-8\") as infile:\n",
        "      data = infile.readlines()\n",
        "\n",
        "  else: \n",
        "    with open(file_path, 'r',encoding=\"ISO-8859-1\") as infile:\n",
        "      data = infile.readlines()\n",
        "\n",
        "  print(\"dataset of size:\", len(data)) \n",
        "  for row in data:\n",
        "    row = row.strip()\n",
        "    info = row.split(\"\\t\")\n",
        "\n",
        "    complex_word = info[1]\n",
        "    complex_words.append(complex_word)\n",
        "    annotations = info[3:]\n",
        "    \n",
        "    if bench:\n",
        "      clean_annotations = [anno[2:] for anno in annotations]\n",
        "    \n",
        "    else: \n",
        "      clean_annotations = annotations\n",
        "\n",
        "    for a in clean_annotations:\n",
        "      all_annos.append(a)\n",
        "  \n",
        "  return all_annos, complex_words"
      ],
      "metadata": {
        "id": "ZFW2KXzaodRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relative_subwords (abs_subwords):\n",
        "  relative_dict = dict()\n",
        "  \n",
        "  total = sum(abs_subwords.values())\n",
        "  \n",
        "  for len, freq in abs_subwords.items():\n",
        "    relative_dict[len] = (freq/total)*100\n",
        "  \n",
        "  return relative_dict\n"
      ],
      "metadata": {
        "id": "5rxOuUz8oeD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_subwordtokenization(tokenizer, words):\n",
        "\n",
        "  tokenize_sizes = defaultdict(int)\n",
        "  for word in words:\n",
        "    tokenized_word = tokenizer.tokenize(word)\n",
        "    nr_of_subwords = len(tokenized_word)\n",
        "    if nr_of_subwords in tokenize_sizes.keys():\n",
        "      tokenize_sizes[nr_of_subwords]+=1\n",
        "    else:\n",
        "      tokenize_sizes[nr_of_subwords]=1\n",
        "  \n",
        "  relative = relative_subwords (tokenize_sizes)\n",
        "\n",
        "  return dict(tokenize_sizes), relative"
      ],
      "metadata": {
        "id": "fn5EZYmPofjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running analysis"
      ],
      "metadata": {
        "id": "JN3Qg8ROomDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")"
      ],
      "metadata": {
        "id": "nPY0BQv9nz0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose file for analysis\n",
        "\n",
        "data_files = [\"/content/BenchLS.txt\", \"/content/lex.mturk.txt\",\"/content/NNSeval.txt\"]\n",
        "# data_files = \"/content/dutch_sents_for_annotation.txt\"]\n",
        "# data_files = [\"/content/dutch_train_sents.txt\"]\n",
        "\n",
        "with open(f\"tokenization_analysis.txt\", \"w\") as outfile:\n",
        "\n",
        "  for file in data_files:\n",
        "    dataset = file.replace(\"/content/\",\"\")\n",
        "    print(dataset)\n",
        "\n",
        "    if \"Bench\" in file or \"NNSeval\" in file or \"dutch\" in file:\n",
        "      annotations, complex_words = get_tokens(file, bench=True)\n",
        "\n",
        "    else: \n",
        "      annotations, complex_words = get_tokens(file, bench=False)\n",
        "\n",
        "    abs_cword, rel_cword = count_subwordtokenization(tokenizer, complex_words)\n",
        "    abs_annos, rel_annos = count_subwordtokenization(tokenizer, annotations)\n",
        "\n",
        "    print(\"percentage of subword tokenized complex words:\",100-rel_cword[1])\n",
        "    print(\"percentage of subword tokenized annotation: \",100-rel_annos[1])\n",
        "\n",
        "    outfile.write(f\"\"\"{dataset}\n",
        "    Complex Words: \n",
        "    \\t Absolute \\t {abs_cword}\n",
        "    \\t Relative \\t {rel_cword}\n",
        "    \\t percentage subword-tokenized \\t {100-rel_cword[1]}\n",
        "    Annotations:\n",
        "    \\t Absolute \\t {abs_annos} \n",
        "    \\t Relative \\t {rel_annos}\n",
        "    \\t percentage subword-tokenized \\t {100-rel_annos[1]}\n",
        "    \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei7HC1uLoukX",
        "outputId": "f902653a-a5c4-45ce-f1e7-c9db6e3b8d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BenchLS.txt\n",
            "dataset of size: 929\n",
            "percentage of subword tokenized complex words: 6.996770721205607\n",
            "percentage of subword tokenized annotation:  12.795793163891318\n",
            "lex.mturk.txt\n",
            "dataset of size: 501\n",
            "percentage of subword tokenized complex words: 11.177644710578832\n",
            "percentage of subword tokenized annotation:  11.33010931848662\n",
            "NNSeval.txt\n",
            "dataset of size: 239\n",
            "percentage of subword tokenized complex words: 7.94979079497908\n",
            "percentage of subword tokenized annotation:  28.92238972640982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Generation Comparison"
      ],
      "metadata": {
        "id": "9AJWlS85tsb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and opening files"
      ],
      "metadata": {
        "id": "bMz7b4_RuLS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the frequency file, and storing it in a dictionary\n",
        "freq_dict = dict()\n",
        "\n",
        "with open (\"/content/frequency_merge_wiki_child.txt\", \"r\") as infile:\n",
        "  data = infile.readlines()\n",
        "\n",
        "for line in data:\n",
        "  line = line.strip()\n",
        "  info = line.split(\" \")\n",
        "  word = info [0]\n",
        "  freq = int(info [1])\n",
        "  freq_dict[word]=freq\n"
      ],
      "metadata": {
        "id": "OvHoCX9KbNDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_lexmturk():\n",
        "  with open (\"/content/lex.mturk.txt\",\"r\",encoding=\"ISO-8859-1\") as infile:\n",
        "    lexmturk = infile.readlines()[1:]\n",
        "\n",
        "  annotations = []\n",
        "  sentences = []\n",
        "  cwords = []\n",
        "  for line in lexmturk:\n",
        "    info = line.strip().split(\"\\t\")\n",
        "    sentence = info[0]\n",
        "    cword = info[1]\n",
        "    line_annotations = [] \n",
        "    for an in  info[2:]:\n",
        "      if an.count(\" \")<1:\n",
        "        line_annotations.append(an)\n",
        "    annotations.append(set(line_annotations))\n",
        "\n",
        "  return annotations, sentences, cwords"
      ],
      "metadata": {
        "id": "63zE8MZBQVjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "Rs8gImt30VN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_characteristics(row):\n",
        "  row = row.strip().split(\"\\t\")\n",
        "  sentence = row[0]\n",
        "  complex_word = row[1]\n",
        "  options = set(row[2:])\n",
        "  \n",
        "  return(sentence, complex_word, options)"
      ],
      "metadata": {
        "id": "VJsxaWPB0UhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comparisons(base_model, other_model, annotations):\n",
        "  prediction_dict = defaultdict(list)\n",
        "\n",
        "  for base_line, model_line, annotations_line in zip(base_model, other_model, annotations):\n",
        "    if len(base_line)>3:\n",
        "      sent, complex_word, base_options = get_characteristics(base_line)\n",
        "    else: continue\n",
        "    if len(model_line)>3:\n",
        "      sent, complex_word, model_options = get_characteristics(model_line)\n",
        "    else: continue\n",
        "    \n",
        "    prediction_dict[\"all_model_preds\"].append(model_options)\n",
        "    prediction_dict[\"all_base_preds\"].append(base_options)\n",
        "\n",
        "    prediction_dict[\"ABM\"].append(base_options.intersection(model_options, annotations_line))\n",
        "    prediction_dict[\"AM\"].append(annotations_line.intersection(model_options).difference(base_options))\n",
        "    prediction_dict[\"AB\"].append(annotations_line.intersection(base_options).difference(model_options))\n",
        "    prediction_dict[\"BM\"].append(base_options.intersection(model_options).difference(annotations_line))\n",
        "    prediction_dict[\"A\"].append(annotations_line.difference(base_options, model_options))\n",
        "    prediction_dict[\"B\"].append(base_options.difference(model_options, annotations_line))\n",
        "    prediction_dict[\"M\"].append(model_options.difference(base_options, annotations_line))\n",
        "\n",
        "    prediction_dict[\"all_preds\"] = base_options.union(model_options, annotations_line)\n",
        "    \n",
        "  return prediction_dict"
      ],
      "metadata": {
        "id": "5oaqeVix0oRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequencies(words):\n",
        "  # word_list = words\n",
        "  word_list = [item for wordset in words for item in wordset]\n",
        "  total_freq = 0\n",
        "  frequencies = []\n",
        "  for word in word_list:\n",
        "    if word in freq_dict.keys():\n",
        "      # print(word)\n",
        "      freq = freq_dict[word]\n",
        "      total_freq += freq\n",
        "      frequencies.append(freq)\n",
        "  \n",
        "  return(frequencies)"
      ],
      "metadata": {
        "id": "vD3DCBFM0a9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos(sents, cwords):\n",
        "  complex_poss = [] \n",
        "  for sent, cword in zip(sents, cwords):\n",
        "    print(sent)\n",
        "    print(cword)\n",
        "    doc = nlp(sent)\n",
        "    pos_sequence = []\n",
        "    tok_sequence = []\n",
        "    for token in doc:\n",
        "      pos_sequence.append(token.pos_)\n",
        "      tok_sequence.append(token.text)\n",
        "    \n",
        "    try:\n",
        "      c_index = tok_sequence.index(cword)\n",
        "      c_pos = pos_sequence[c_index]\n",
        "    \n",
        "    except:\n",
        "      c_pos = \"NONE\"\n",
        "    complex_poss.append(c_pos)\n",
        "    \n",
        "  return complex_poss"
      ],
      "metadata": {
        "id": "eKcMtWOIEnXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "7E2YHwV_0ceD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "mypath = \"/content/ouputs\"\n",
        "print(models_to_analyze)\n",
        "models_to_analyze = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzluRLCW5UN",
        "outputId": "5ff22a9d-2fee-4b00-f8a7-f1e51909c220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lex.mturk_FT_lr5e-07_50000sents_outputs.txt', 'lex.mturk_FT_lr5e-07_1000sents_outputs.txt', '.ipynb_checkpoints', 'lex.mturk_FT_lr5e-06_50000sents_outputs.txt', 'lex.mturk_FT_lr0.0005_1000sents_outputs.txt', 'lex.mturk_FT_lr0.0005_50000sents_outputs.txt', 'lex.mturk_FT_lr5e-06_1000sents_outputs.txt', 'lex.mturk_FT_lr0.0005_10000sents_outputs.txt', 'lex.mturk_FT_lr5e-05_1000sents_outputs.txt', 'lex.mturk_FT_lr5e-06_10000sents_outputs.txt', 'lex.mturk_FT_lr5e-07_10000sents_outputs.txt', 'lex.mturk_FT_lr5e-05_50000sents_outputs.txt', 'lex.mturk_FT_lr5e-05_10000sents_outputs.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open Base Model File:\n",
        "wwm_path = \"/content/LMTWWMoutputs.txt\"\n",
        "with open (wwm_path, \"r\") as infile:\n",
        "  base_model = infile.readlines()  \n",
        "\n",
        "# Open Annotation File\n",
        "annotations, sentences, cwords = open_lexmturk()\n",
        "\n",
        "# Load Stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# List of complex word POSs\n",
        "pos_list = get_pos(sentences, cwords)\n",
        "\n",
        "# List of model outputs to analyze\n",
        "# models_to_analyze = [\"/content/lex.mturk_FT_lr5e-06_10000sents_outputs.txt\",\n",
        "                    #  \"/content/lex.mturk_FT_lr5e-07_1000sents_outputs.txt\"] "
      ],
      "metadata": {
        "id": "khbstdVe0duv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"generation_analysis.csv\",\"w\") as outfile:\n",
        "\n",
        "  # Write Header\n",
        "  outfile.write(\"model_name\\tsetting\\t occurence\\t avg_tok_len\\t median\\t sigma\\t stop_word_count\\t stop_word_unique\\n\")\n",
        "\n",
        "  # Analysis for each of the model outputs\n",
        "  for model_to_analyze in models_to_analyze:\n",
        "\n",
        "    model_name = model_to_analyze.replace(\"/content/\",\"\")\n",
        "    model_path = \"/content/ouputs/\"+model_to_analyze\n",
        "\n",
        "    with open (model_path, \"r\") as infile:\n",
        "      model = infile.readlines()\n",
        "      comparisons = get_comparisons(base_model, model, annotations)\n",
        "\n",
        "      for name, setting in comparisons.items():\n",
        "        print(\"\\nSetting:\",name)\n",
        "\n",
        "        frequencies = get_frequencies(setting)\n",
        "        occurence = len(frequencies)\n",
        "        print(\"This setting occured\", occurence, \"times\")\n",
        "\n",
        "        # If this setting has at least one overlapping prediction:\n",
        "        if occurence> 1:\n",
        "        \n",
        "          flattened =  [item for wordset in setting for item in wordset]\n",
        "          lengths = [len(i) for i in flattened]\n",
        "          \n",
        "          # Amount of generated stopwords\n",
        "          stop_word_count = 0  \n",
        "          for stop_word in stop_words:\n",
        "            stop_word_count += flattened.count(stop_word)\n",
        "          stop_word_unique = len(stop_words.intersection(set(flattened)))\n",
        "\n",
        "          # Frequency statistics\n",
        "          avg_tok_len = sum(lengths) / len(lengths)\n",
        "          print(avg_tok_len)\n",
        "          median = statistics.median(frequencies)\n",
        "          sigma = statistics.stdev(frequencies)\n",
        "          \n",
        "        else:\n",
        "          stop_word_count = 0\n",
        "          stop_word_unique = 0\n",
        "          avg_tok_len = 0\n",
        "          median = 0\n",
        "          sigma = 0\n",
        "        \n",
        "        outfile.write(model_name+\"\\t\"+\n",
        "                      name+\"\\t\"+\n",
        "                      str(occurence)+\"\\t\"+\n",
        "                      str(avg_tok_len)+\"\\t\"+\n",
        "                      str(median)+\"\\t\"+\n",
        "                      str(sigma)+\"\\t\"+\n",
        "                      str(stop_word_count)+\"\\t\"+\n",
        "                      str(stop_word_unique)+\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC-UV0sS0fuE",
        "outputId": "fcf01b6c-9fb8-476a-b8e7-d0c595fce911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 4998 times\n",
            "7.5754301720688275\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1190 times\n",
            "6.81344537815126\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 218 times\n",
            "6.477064220183486\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 289 times\n",
            "6.73356401384083\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 2063 times\n",
            "7.965584100824042\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3374 times\n",
            "6.878685762426285\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1458 times\n",
            "7.502057613168724\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1527 times\n",
            "7.798952193844139\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 112 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 4980 times\n",
            "7.327510040160643\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1028 times\n",
            "6.761673151750973\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 199 times\n",
            "6.57286432160804\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 451 times\n",
            "6.880266075388026\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1564 times\n",
            "7.835677749360614\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3393 times\n",
            "6.87122905027933\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1957 times\n",
            "7.724067450178845\n",
            "\n",
            "Setting: M\n",
            "This setting occured 2189 times\n",
            "7.298766560073092\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 123 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 5000 times\n",
            "7.4788\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1205 times\n",
            "6.829875518672199\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 341 times\n",
            "6.5337243401759535\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 274 times\n",
            "6.656934306569343\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1853 times\n",
            "7.886130599028602\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3251 times\n",
            "6.887434554973822\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1668 times\n",
            "7.648681055155875\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1601 times\n",
            "7.697064334790756\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 108 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 3500 times\n",
            "1.856\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1 times\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 0 times\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 1478 times\n",
            "6.8010825439783495\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 14 times\n",
            "2.2857142857142856\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3592 times\n",
            "6.855517332627679\n",
            "\n",
            "Setting: B\n",
            "This setting occured 3507 times\n",
            "7.795551753635586\n",
            "\n",
            "Setting: M\n",
            "This setting occured 3485 times\n",
            "1.854232424677188\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 106 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 3998 times\n",
            "1.7493746873436717\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1 times\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 0 times\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 1478 times\n",
            "6.8010825439783495\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 14 times\n",
            "2.2857142857142856\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3592 times\n",
            "6.855517332627679\n",
            "\n",
            "Setting: B\n",
            "This setting occured 3507 times\n",
            "7.795551753635586\n",
            "\n",
            "Setting: M\n",
            "This setting occured 3983 times\n",
            "1.7474265628922923\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 107 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 4963 times\n",
            "7.573040499697764\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1134 times\n",
            "6.85626102292769\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 204 times\n",
            "6.794117647058823\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 345 times\n",
            "6.605797101449276\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1912 times\n",
            "7.898535564853557\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3388 times\n",
            "6.859020979020979\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1609 times\n",
            "7.625233064014916\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1713 times\n",
            "7.776999416228838\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 117 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 3500 times\n",
            "1.570857142857143\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1 times\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 0 times\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 1478 times\n",
            "6.8010825439783495\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 12 times\n",
            "2.1666666666666665\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3592 times\n",
            "6.855517332627679\n",
            "\n",
            "Setting: B\n",
            "This setting occured 3509 times\n",
            "7.792818466799658\n",
            "\n",
            "Setting: M\n",
            "This setting occured 3487 times\n",
            "1.568683682248351\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 104 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 4988 times\n",
            "7.5386928628708905\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1085 times\n",
            "6.766820276497696\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 342 times\n",
            "6.62280701754386\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 394 times\n",
            "6.883248730964467\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1440 times\n",
            "7.936111111111111\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3250 times\n",
            "6.878673261565319\n",
            "\n",
            "Setting: B\n",
            "This setting occured 2081 times\n",
            "7.6612205670350795\n",
            "\n",
            "Setting: M\n",
            "This setting occured 2121 times\n",
            "7.811409712399811\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 134 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 5000 times\n",
            "7.347\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1318 times\n",
            "6.783004552352049\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 356 times\n",
            "6.297752808988764\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 161 times\n",
            "6.919254658385094\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 2148 times\n",
            "7.827281191806332\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3236 times\n",
            "6.913526146654981\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1373 times\n",
            "7.689730517115805\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1178 times\n",
            "7.419354838709677\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 110 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 4978 times\n",
            "7.493772599437525\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1116 times\n",
            "6.804659498207886\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 183 times\n",
            "6.6502732240437155\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 363 times\n",
            "6.776859504132231\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1892 times\n",
            "7.847251585623678\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3409 times\n",
            "6.865962180200222\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1629 times\n",
            "7.688152240638429\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1787 times\n",
            "7.636261891438164\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 108 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 3500 times\n",
            "1.5714285714285714\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1 times\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 0 times\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 1478 times\n",
            "6.8010825439783495\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 12 times\n",
            "2.1666666666666665\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3592 times\n",
            "6.855517332627679\n",
            "\n",
            "Setting: B\n",
            "This setting occured 3509 times\n",
            "7.792818466799658\n",
            "\n",
            "Setting: M\n",
            "This setting occured 3487 times\n",
            "1.5692572411815313\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 104 times\n",
            "1.0\n",
            "\n",
            "Setting: all_model_preds\n",
            "This setting occured 5000 times\n",
            "7.2618\n",
            "\n",
            "Setting: all_base_preds\n",
            "This setting occured 5000 times\n",
            "7.485\n",
            "\n",
            "Setting: ABM\n",
            "This setting occured 1180 times\n",
            "6.726271186440678\n",
            "\n",
            "Setting: AM\n",
            "This setting occured 431 times\n",
            "6.336426914153132\n",
            "\n",
            "Setting: AB\n",
            "This setting occured 299 times\n",
            "7.080267558528428\n",
            "\n",
            "Setting: BM\n",
            "This setting occured 1597 times\n",
            "7.792736380713839\n",
            "\n",
            "Setting: A\n",
            "This setting occured 3161 times\n",
            "6.922341696535245\n",
            "\n",
            "Setting: B\n",
            "This setting occured 1924 times\n",
            "7.757796257796258\n",
            "\n",
            "Setting: M\n",
            "This setting occured 1792 times\n",
            "7.363839285714286\n",
            "\n",
            "Setting: all_preds\n",
            "This setting occured 133 times\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dutch: Analysis of non-word predictions"
      ],
      "metadata": {
        "id": "9vaGeIsKKy8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Thesis/code/Dutch/Error Analysis/outputs.txt\",\"r\") as infile:\n",
        "  data = infile.readlines()"
      ],
      "metadata": {
        "id": "j4t4smWTK7vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))\n",
        "only_chars = [] \n",
        "also_chars = []\n",
        "\n",
        "for row in data:\n",
        "  info = row.strip().split(\"\\t\")\n",
        "  sentence = info [0]\n",
        "  cword = info [1]\n",
        "  predictions = info[2:]\n",
        "  one_char_preds = len([i for i in predictions if len(i)==1])\n",
        "\n",
        "  if one_char_preds == 0:\n",
        "    continue\n",
        "  elif one_char_preds in range(1,10):\n",
        "    also_chars.append(row)\n",
        "    print(\"less than ten\")\n",
        "    print(sentence, cword, predictions)\n",
        "  else: \n",
        "    only_chars.append(row)\n",
        "    print(\"there are ten\")\n",
        "    print(sentence, cword, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAZRpr8xLHnp",
        "outputId": "9f9f6947-f998-46ca-d8e6-0843d7abeb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "less than ten\n",
            "De gemeente Amsterdam stimuleert mobiliteit en heeft daarbij ook aandacht voor de mogelijkheden van promotie en demotie. stimuleert ['biedt', 'steunt', 'bevorderd', 'gestimuleerd', 'c', 'l', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "prestatie met bijbehorend stimulerend gedrag. stimulerend ['gezond', 'positief', 'prettig', 'aantrekkelijk', 'creatief', 'o', 'l', 'i', 'i', 'i']\n",
            "less than ten\n",
            "Geef aandacht aan diversiteit, b.v. door verschillende feestdagen te vieren diversiteit ['cultuur', 'schoonheid', 'innovatie', 'à', 'j', 'j', 'j', 'j', 'j', 'j']\n",
            "there are ten\n",
            "Daar kun je het met elkaar over hebben. daar ['m', 'i', 'p', 'k', 'à', 'è', 'è', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Ook vervult de monitor een verantwoordingsfunctie. monitor ['bestuurder', 'voorzitter', 'burgemeester', 'directeur', 'werknemer', 'ambtenaar', 'secretaris', 'c', 'c', 'c']\n",
            "less than ten\n",
            "van ‘High Impact Crime’ (HIC) die in 2011 in de regio Amsterdam-Amstelland is opgezet. impact ['effect', 't', 'à', 'i', 'y', 'y', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "De in 2018 binnengekomen meldingen tonen kleine toename van professionele en organisatorische diversiteit in de achtergrond van de melders. diversiteit ['verschillen', 'kwaliteit', 'variatie', 'cultuur', 'omvang', 'à', 'afkomst', 'afkomst', 'afkomst', 'afkomst']\n",
            "less than ten\n",
            "Naar alle waarschijnlijkheid kunnen de geselecteerde gezinnen in het voorjaar van 2019 in de pilot worden opgenomen. pilot ['serie', 'proef', 'selectie', 'u', 'r', 'r', 'r', 'r', 'r', 'r']\n",
            "less than ten\n",
            "AcVZ: inzet op complexe casuïstiek complexe ['eenvoudige', 'ingewikkelde', 'logische', 'à', 'ú', 'ú', 'ú', 'ú', 'ú', 'ú']\n",
            "less than ten\n",
            "De gedachte erachter is dat een complex probleem nooit op zichzelf staat: complex ['ingewikkeld', 'persoonlijk', 'eenvoudig', 'volledig', 'dergelijk', 'bepaald', 'ander', 'h', 'i', 'i']\n",
            "less than ten\n",
            "De dagelijkse leiding ligt bij een programmamanager die een aantal projectleiders aanstuurt. aanstuurt ['stuurt', 'helpt', 'traint', 'levert', 'inzet', 'o', 'o', 'o', 'o', 'o']\n",
            "less than ten\n",
            "Daar zit een uitdaging voor de komende periode. daar ['er', 'hier', 'm', 'u', 'à', 'g', 'è', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Zingen, dansen, spel, bewegen en ontdekken, daar gaat het om. daar ['hier', 'overal', 'waar', 'zo', 'k', 'à', 'r', 'è', 'l', 'l']\n",
            "there are ten\n",
            "Daar hoef je zelf niets voor te doen. daar ['m', 't', 'à', 'k', 'ï', 'i', 'i', 'i', 'i', 'i']\n",
            "less than ten\n",
            "Dat is puur administratief en daar merk jij niets van. daar ['hier', 'er', 'waar', 'overal', 'dat', 'ergens', 'die', 'à', 'k', 'k']\n",
            "less than ten\n",
            "Hoe dat allemaal precies in zijn werk gaat, daar informeren we je later dit jaar verder over. daar ['hier', 'k', 'u', 'à', 'x', 'i', 'ï', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Vanaf medio januari 2020 kun je weer inloggen, maar dan in het nieuwe systeem. medio ['1', 'eind', 'begin', 'half', '15', '31', '30', 'halverwege', '25', 'midden']\n",
            "less than ten\n",
            "Deze nota gaat daar verder niet op in. daar ['hier', 'er', 'waar', 'verder', 'dus', 'ergens', 'à', 'f', 'f', 'f']\n",
            "less than ten\n",
            "Maatregel 18: stimuleren transport over water stimuleren ['meer', 'verbieden', 'l', 'promoten', 'x', 'o', 'j', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Maatregel stimuleren transport over water stimuleren ['van', 'ontmoedigen', 'verbieden', 'promoten', 'bevorderen', 'verlagen', 'à', 'reguleren', 'l', 'l']\n",
            "less than ten\n",
            "In de tweede helft van 2019 wordt aan de branche gevraagd voorstellen voor deze pilots te doen. pilots ['diensten', 'projecten', 'experimenten', 'modellen', 'contracten', 'producten', 'winkels', 'à', 'à', 'à']\n",
            "less than ten\n",
            "Aan de hand van een afwegingskader zal de gemeente keuze voor de pilots maken. pilots ['locaties', 'x', 'bussen', 'à', 'projecten', 'l', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "Wij gebruiken persoonsgegevens alleen als daar een grondslag voor is. daar ['hier', 'er', 'ergens', 'waar', 'dat', 'nergens', 'overal', 'à', 't', 't']\n",
            "less than ten\n",
            "De komende tijd moet de organisatie daar invulling aan geven. daar ['hier', 'er', 'meer', 'o', 'c', 'k', 'j', 'i', 'i', 'i']\n",
            "less than ten\n",
            "Daar wordt nu al druk mee geoefend. daar ['er', 'hier', 'm', 'à', 'k', 'k', 'k', 'k', 'k', 'k']\n",
            "less than ten\n",
            "Hoewel het evenement goed is verlopen is er een aantal aandachtspunten met betrekking tot de samenwerking met de organisatie. hoewel ['als', 'u', 'u', 'u', 'u', 'u', 'u', 'u', 'u', 'u']\n",
            "less than ten\n",
            "Met ingang van 21 maart 2018 is de Verordening op het lokaal bestuur in Amsterdam in werking getreden. verordening ['wet', 'controle', 'werking', 'ï', 'r', 'è', 'x', 'x', 'x', 'x']\n",
            "less than ten\n",
            "De inspecteur vaarwegen kan daarbij gebruik maken van diverse vormen van sanctioneren. sanctioneren ['vervoer', 'controle', 'varen', 'transport', 'u', 'surveillance', 'toezicht', 'scheepvaart', 'à', 'à']\n",
            "less than ten\n",
            "Het werken aan de opgave voor Amsterdam en de Amsterdammers staat centraal. opgave ['toekomst', 'kandidaten', 'lijst', 'lijsten', 'j', 'ï', 'ï', 'ï', 'ï', 'ï']\n",
            "less than ten\n",
            "Indien er sprake is van een adviestraject met de OR dan maakt de participatieparagraaf onderdeel uit van de adviesaanvraag. indien ['als', 'wanneer', 'mits', 'i', 'u', 'j', 'j', 'j', 'j', 'j']\n",
            "less than ten\n",
            "Daarom wordt gestart bij de expertises van de projectinrichting. expertises ['onderdelen', 'à', 'projecten', 'r', 'y', 'y', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "Een kwartiermaker is iemand die partijen samenbrengt, inspireert en iets nieuws creëert. creëert ['schept', 'brengt', 'maakt', 'verzamelt', 'vormt', 'ontwikkelt', 'plant', 'l', 'l', 'l']\n",
            "less than ten\n",
            "Wie zijn de stakeholders en hoe zet je die in? stakeholders ['vrijwilligers', 'mensen', 'arbeiders', 'mannen', 'y', 'm', 'm', 'm', 'm', 'm']\n",
            "there are ten\n",
            "Echter een organisatieontwerp is meer dan alleen een getekend harkje, een organogram. echter ['n', 'a', 'à', 'à', 'à', 'à', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "Richt je in naar functies (spelers) of naar expertises (rollen). expertises ['functies', 'diensten', 'teams', 'vaardigheden', 'taken', 'netwerken', 'prestaties', 'trainingen', 'à', 'à']\n",
            "less than ten\n",
            "Indien de FIF wordt aangepast, zal de manager dit tekstvoorstel voorleggen aan de medewerker. indien ['als', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j']\n",
            "less than ten\n",
            "Categorie 2: Sterk gewijzigde en nieuwe functies categorie ['klasse', 'a', 'n', 'à', 'x', 'q', 'q', 'q', 'q', 'q']\n",
            "less than ten\n",
            "Uitvoering van de implementatie fase implementatie ['eerste', 'nieuwe', 'tweede', 'derde', 'volgende', 'a', 't', 'à', 'à', 'à']\n",
            "less than ten\n",
            "De functie blijft bestaan in dezelfde of licht gewijzigde vorm, dit is een ‘categorie 1’ functie. categorie ['groep', 'klasse', 'type', 'fase', 'klas', 'reeks', 'kader', 'g', 'g', 'g']\n",
            "there are ten\n",
            "Voor management vacatures geldt het criterium van geschiktheid (NRGA). criterium ['j', 'a', 'x', 'à', 'k', 'l', 'l', 'l', 'l', 'l']\n",
            "there are ten\n",
            "de mutaties verwerkt worden. mutaties ['g', 'à', 'a', 'o', 'x', 'q', 'è', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Als organisatie willen we onze afdelingen, teams en medewerkers zo goed mogelijk faciliteren in hun leer- en ontwikkelvragen. faciliteren ['ondersteunen', 'begeleiden', 'helpen', 'steunen', 'integreren', 'o', 'j', 'è', 'l', 'l']\n",
            "there are ten\n",
            "Interventies die uitnodigen om voortdurend te (zelf)reflecteren, leren en verbeteren. interventies ['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n",
            "less than ten\n",
            "Deze doelgroep heeft een sleutelrol in vernieuwing en de richting waarin de organisatie zich ontwikkelt. ontwikkelt ['richt', 'groeit', 'verplaatst', 'o', 'afspeelt', 'l', 'y', 'ú', 'ú', 'ú']\n",
            "there are ten\n",
            "monitoren (hacken, cyberpesten, koop- en verkoopfraude en identiteitsfraude); monitoren ['à', 'x', 'g', 'è', 'è', 'è', 'è', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Hierdoor ontstaat in de monitor zowel een subjectieve als objectief beeld van digitale veiligheid en het welzijn van burgers. monitor ['film', 'video', 'o', 't', 'r', 'n', 'n', 'n', 'n', 'n']\n",
            "there are ten\n",
            "Immers, uitval gaat gebeuren. immers ['à', 'k', 'm', 'y', 't', 'j', 'j', 'j', 'j', 'j']\n",
            "there are ten\n",
            "De taken van de taskforce bestaan uit: taskforce ['j', 'q', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "een eerste verkenning op hoofdlijnen. hoofdlijnen ['basis', 'termijn', 'à', 'r', 'netwerken', 'a', 'm', 'q', 'ú', 'ú']\n",
            "less than ten\n",
            "Ook zijn ontwikkelingen landelijk in de evaluatie opgenomen, evenals bevindingen voor de gemeente Amsterdam uit eerder onderzoek. evaluatie ['rapportage', 'beoordeling', 'studie', 'analyse', 'geëvalueerd', 'u', 'y', 'g', 'g', 'g']\n",
            "less than ten\n",
            "een eerste verkenning op hoofdlijnen. hoofdlijnen ['basis', 'termijn', 'à', 'r', 'netwerken', 'a', 'm', 'q', 'ú', 'ú']\n",
            "less than ten\n",
            "Niet alle jongeren lopen daar warm voor. daar ['er', 'hier', 'ergens', 'dat', 'overal', 'ook', 'à', 'i', 'á', 'á']\n",
            "less than ten\n",
            "Daarin zijn geen studieschulden van DUO meegenomen. meegenomen ['aangegeven', 'teruggevonden', 'a', 'teruggebracht', 'à', 'ingevoerd', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "De onderzoekers van Kredietcrisis onder risicojongeren onderscheidde in het proces naar een oplossing vijf ontwikkelstadia. onderscheidde ['waren', 'werden', 'werkten', 'a', 'l', 'l', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "Niet alleen raak je daar de controle mee kwijt, het is ook een deuk in je eigenwaarde. daar ['er', 'hier', 'overal', 'ergens', 'waar', 'dat', 'die', 'k', 'à', 'à']\n",
            "less than ten\n",
            "Gesprekstechnieken en methoden zoals motiverende gespreksvoering kunnen in dat kader worden ingezet. motiverende ['de', 'directe', 'alternatieve', 'kalme', 'l', 'à', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "De methode motiverende gespreksvoering is waarschijnlijk de bekendste. motiverende ['van', 'voor', 'à', 'l', 'l', 'l', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "Interventies moeten dus zowel gericht zijn op het compenseren van bepaalde functies, als op het aanleren ervan. interventies ['ze', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n",
            "less than ten\n",
            "Sinds kort is in Amsterdam Zuid-Oost met Madizo de pilot Geld Gappie gestart. pilot ['eerste', 'clean', 'mix', 'stop', 'tweede', 'o', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "Het stadsdeel met de meest kwetsbare doelgroep jongeren (Zuid-Oost), had een laag bereikt potentieel. potentieel ['bereik', 'gebied', 'aandeel', 'vermogen', 'aanbod', 'embleem', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "Er worden praktische aanbevelingen gedaan die betrekking hebben op interventies en de inrichting van schuldhulpverlening. interventies ['operaties', 'hulpverlening', 'acties', 'hulp', 'preventie', 'ondersteuning', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "Uit de evaluatie is het outreachend werken niet sterk naar voren gekomen als een onderdeel van het dagelijkse werk. evaluatie ['analyse', 'studie', 'rapportage', 'beoordeling', 'x', 'à', 'è', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Uit de evaluatie kwam naar voren dat hier niet bij elke organisatie voldoende aandacht voor was. evaluatie ['test', 'analyse', 'rapportage', 'tests', 'beoordeling', 'studie', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "Uit de inventarisatie kwam vooral naar voren dat men positief is over de samenwerking. inventarisatie ['analyse', 'gegevens', 'cijfers', 'presentatie', 'database', 'rapportage', 'x', 'x', 'x', 'x']\n",
            "less than ten\n",
            "De effecten van het Coronabeleid lijken daar de oorzaak van te zijn. daar ['hier', 'er', 'overal', 'ergens', 'ook', 'à', 'k', 't', 'f', 'f']\n",
            "less than ten\n",
            "Zie bijlage 4 voor het volledige overzicht van de evaluatie. evaluatie ['resultaten', 'tests', 'aanvraag', 'beoordeling', 'u', 'bevindingen', 'y', 'à', 'à', 'à']\n",
            "less than ten\n",
            "Uit de evaluatie komt naar voren dat er in de intakefase veel gedaan wordt voor de jongeren. evaluatie ['studie', 'resultaten', 'rapportage', 'analyse', 'u', 'beoordeling', 'j', 'g', 'g', 'g']\n",
            "less than ten\n",
            "Het gebruik van de term ‘DFD’ in de communicatie met schuldeisers zou daar ook aan kunnen bijdragen. daar ['hier', 'er', 'dat', 'ergens', 'dan', 'dus', 'i', 'à', 'k', 'k']\n",
            "less than ten\n",
            "Uit de evaluatie is naar voren gekomen dat zich dit positief vertaalt in de doorlooptijden van de dossiers. evaluatie ['test', 'analyse', 'studie', 'beoordeling', 'tests', 'rapportage', 'u', 'y', 'y', 'y']\n",
            "less than ten\n",
            "Daar wordt hij eerst geholpen door een trajectbegeleider van PerMens. daar ['hier', 'c', 'j', 'ï', 'k', 'x', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "een eerste verkenning op hoofdlijnen. hoofdlijnen ['basis', 'termijn', 'à', 'r', 'netwerken', 'a', 'm', 'q', 'ú', 'ú']\n",
            "less than ten\n",
            "- Inzicht hebben in lukken, ondersteunen naar vermogen, inzetten op doenvermogen. vermogen ['kracht', 'kapitaal', 'energie', 'lichaam', 'volume', 't', 'g', 'goed', 'i', 'i']\n",
            "less than ten\n",
            "Op [DATUM] heeft u het Bibob-formulier ingediend en daarop “nee” geantwoord op bovenstaande vraag. bovenstaande ['deze', 'die', 'dezelfde', 'de', 'genoemde', 'uw', 'ú', 'ú', 'ú', 'ú']\n",
            "less than ten\n",
            "Als u het niet eens bent met een gemeentelijk besluit kunt u daar bezwaar tegen maken. daar ['er', 'hier', 'overal', 'nergens', 'i', 'à', 'k', 'k', 'k', 'k']\n",
            "less than ten\n",
            "Een aantal grotere saldo neutrale mutaties zijn: mutaties ['soorten', 'a', 'g', 'á', 'j', 'i', 'i', 'i', 'i', 'i']\n",
            "less than ten\n",
            "Met structureel evenwicht wordt bedoeld dat structurele lasten worden gedekt door structurele baten. structureel ['dit', 'dergelijk', 'dat', 'economisch', 'primair', 't', 'o', 'i', 'i', 'i']\n",
            "less than ten\n",
            "Onderstaande afwijkingen per programma geven op hoofdlijnen een verklaring voor dit verschil. hoofdlijnen ['basis', 'lijnen', 'termijn', 'punten', 'punt', 'onderdelen', 'schema', 'pagina', 'a', 'a']\n",
            "less than ten\n",
            "En dat betekent dat we daar zorgvuldig mee om moeten gaan. daar ['er', 'hier', 'ergens', 'overal', 'waar', 'dat', 'heel', 'k', 'i', 'i']\n",
            "there are ten\n",
            "Daar organiseren wij ons flexibel op. daar ['à', 'à', 'à', 'à', 'à', 'à', 'à', 'à', 'à', 'à']\n",
            "there are ten\n",
            "Diversiteit staat hierbij voorop. diversiteit ['à', 'm', 'n', 'y', 'p', 'p', 'p', 'p', 'p', 'p']\n",
            "there are ten\n",
            "Diversiteit staat hierbij voorop. diversiteit ['à', 'm', 'n', 'y', 'p', 'p', 'p', 'p', 'p', 'p']\n",
            "there are ten\n",
            "Resumerend: als een bestuursorgaan zijn beslissingen baseert op een computerprogramma/algoritme moet het op grond van de AERIUS-uitspraken: resumerend ['n', 't', 'j', 'x', 'l', 'i', 'i', 'i', 'i', 'i']\n",
            "less than ten\n",
            "specifieke voorspellende data; de belangrijkste policy keuzes die gemaakt zijn; specifieke ['de', 'bepaalde', 'andere', 'primaire', 'exacte', 'j', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "welke wijzigingen in de input zouden moeten worden doorgevoerd om tot een andere uitkomst te komen. input ['procedure', 'tekst', 'wet', 'inhoud', 'procedures', 'regelgeving', 'wetgeving', 'uitslag', 'y', 'y']\n",
            "less than ten\n",
            "Hierbij is de regulier genormeerde residuele benadering uitgangspunt. regulier ['meer', 'à', 'huidige', 'o', 'j', 'q', 'l', 'l', 'l', 'l']\n",
            "less than ten\n",
            "Toch kent kenmerkt Terrasdorp zich nog steeds door een concentratie van huishoudens met lage inkomens. concentratie ['reeks', 'afname', 'cluster', 'veelvoud', 'keten', 'verzameling', 'i', 't', 't', 't']\n",
            "there are ten\n",
            "Qua spelen is het in de directe omgeving niet overmatig goed gesteld. qua ['n', 'g', 'à', 'à', 'à', 'à', 'à', 'à', 'à', 'à']\n",
            "less than ten\n",
            "in veel opzichten gaat het over transitie. transitie ['macht', 'à', 'y', 'j', 'x', 'é', 'q', 'q', 'q', 'q']\n",
            "less than ten\n",
            "Ook is er gekeken naar de specifieke specifieke ['categorie', 'g', 'j', 'y', 'q', 'q', 'q', 'q', 'q', 'q']\n",
            "less than ten\n",
            "De relatie noord-zuid kan bijvoorbeeld worden verbeterd. relatie ['verhouding', 'verbinding', 'scheiding', 'combinatie', 'lijn', 'samenwerking', 'r', 'i', 'betrekking', 'betrekking']\n",
            "less than ten\n",
            "Op landelijk niveau is het streven om in 2030 50% minder primaire grondstoffen te gebruiken. primaire ['duurzame', 'industriële', 'belangrijke', 'zware', 'liquide', 'vrije', 'à', 'ú', 'ú', 'ú']\n",
            "less than ten\n",
            "Relatie leggen met eerdere bijeenkomsten en besluiten. relatie ['contact', 'link', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c']\n",
            "less than ten\n",
            "optimaliseren van het stedenbouwkundig en verkeerskundig profiel: optimaliseren ['verbeteren', 'aanpassen', 'wijzigen', 'verkleinen', 'j', 'definiëren', 'vernieuwen', 'è', 'è', 'è']\n",
            "less than ten\n",
            "Samenwerking met de exploitant om te zorgen dat de horecagelegenheid voldoet aan zijn wensen en behoeften. voldoet ['doet', 'beantwoord', 'blijft', 'aangepast', 'bouwt', 'o', 'y', 'y', 'y', 'y']\n",
            "less than ten\n",
            "Ook De Nijs, die de herontwikkeling van het KPMG-gebouw doet, heeft daar een bijdrage aan geleverd. daar ['er', 'hier', 'ergens', 'dat', 'die', 't', 'k', 'à', 'á', 'á']\n",
            "less than ten\n",
            "Daar werken zij in stappen naartoe. daar ['hier', 'k', 'à', 'j', 'è', 'è', 'è', 'è', 'è', 'è']\n",
            "there are ten\n",
            "De Taskforce bestond verder uit vertegenwoordigers van de gemeente Amsterdam, Uber en het ministerie van Infrastructuur en Waterstaat. taskforce ['j', 'q', 'i', 'n', 'c', 'y', 'x', 'è', 'è', 'è']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"only_chars.txt\",\"w\") as outfile:\n",
        "  outfile.writelines(only_chars)\n",
        "\n",
        "with open (\"also_chars.txt\",\"w\") as outfile:\n",
        "  outfile.writelines(also_chars)"
      ],
      "metadata": {
        "id": "VOdSS-KdLJIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Selection Analysis"
      ],
      "metadata": {
        "id": "YPH6pBlyHgqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NoliwO5IHn-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}